{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# plotting\n",
    "import matplotlib as mpl\n",
    "mpl.style.use('ggplot')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# math and data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# to handle paths\n",
    "from pathlib import Path\n",
    "\n",
    "# set random seeds \n",
    "from numpy.random import seed\n",
    "from tensorflow import set_random_seed\n",
    "\n",
    "# Tensorflow\n",
    "from tensorflow import keras \n",
    "import tensorflow as tf\n",
    "\n",
    "# progress bar\n",
    "from tqdm import tqdm\n",
    "\n",
    "from csef.utils import performance\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "RANDOM_SEED = 2018\n",
    "seed(RANDOM_SEED)\n",
    "set_random_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path('..', '..', 'data', 'raw')\n",
    "consumption_train = pd.read_csv(data_path / 'consumption_train.csv', \n",
    "                                index_col=0, parse_dates=['timestamp'])\n",
    "cold_start_test = pd.read_csv(data_path / 'cold_start_test.csv', \n",
    "                              index_col=0, parse_dates=['timestamp'])\n",
    "submission_format = pd.read_csv(data_path / 'submission_format.csv',\n",
    "                                index_col='pred_id',\n",
    "                                parse_dates=['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit a model\n",
    "def model_build(config, loss='mean_absolute_error', optimizer='adam', stateful=True):\n",
    "    n_input, n_nodes, n_batch = config\n",
    "\n",
    "    # model parameters\n",
    "    # n_batch should be 1 \n",
    "    lag = n_input\n",
    "    batch_input_shape=(n_batch, 1, lag)\n",
    "\n",
    "    # instantiate a sequential model\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    # add LSTM layer - stateful MUST be true here in \n",
    "    # order to learn the patterns within a series\n",
    "    model.add(keras.layers.LSTM(units=n_nodes, \n",
    "                  batch_input_shape=batch_input_shape, \n",
    "                  stateful=stateful))\n",
    "\n",
    "    # followed by a dense layer with a single output for regression\n",
    "    model.add(keras.layers.Dense(1))\n",
    "\n",
    "    # compile\n",
    "    model.compile(loss=loss, optimizer=optimizer)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def model_fit(model, train_df, config, train_col='consumption', group_col='series_id'):\n",
    "    n_input, _, n_batch = config\n",
    "\n",
    "    for ser_id, ser_data in train_df.groupby(group_col):\n",
    "\n",
    "        # prepare the data\n",
    "        X, y, scaler = prepare_training_data(ser_data[train_col], n_input)\n",
    "\n",
    "        # fit the model: note that we don't shuffle batches (it would ruin the sequence)\n",
    "        # and that we reset states only after an entire X has been fit, instead of after\n",
    "        # each (size 1) batch, as is the case when stateful=False\n",
    "        model.fit(X, y, epochs=1, batch_size=n_batch, verbose=0, shuffle=False)\n",
    "        model.reset_states()\n",
    "\n",
    "    return model\n",
    "\n",
    "# forecast with a pre-fit model\n",
    "def model_predict(model, consumption, config, scaler, num_pred_hours=24, is_inverse_transform=True):\n",
    "    n_input, _, _ = config\n",
    "    \n",
    "    # allocate prediction frame\n",
    "    preds_scaled = np.zeros(num_pred_hours)\n",
    "    \n",
    "    # initial X is last lag values from the cold start\n",
    "    X = scaler.transform(consumption.values.reshape(-1, 1))[-n_input:]\n",
    "    \n",
    "    # forecast\n",
    "    for i in range(num_pred_hours):\n",
    "        # predict scaled value for next time step\n",
    "        yhat = model.predict(X.reshape(1, 1, n_input), batch_size=1)[0][0]\n",
    "        preds_scaled[i] = yhat\n",
    "        \n",
    "        # update X to be latest data plus prediction\n",
    "        X = pd.Series(X.ravel()).shift(-1).fillna(yhat).values\n",
    "\n",
    "    # revert scale back to original range\n",
    "    if is_inverse_transform:\n",
    "        hourly_preds = scaler.inverse_transform(preds_scaled.reshape(-1, 1)).ravel()\n",
    "    else:\n",
    "        hourly_preds = preds_scaled\n",
    "\n",
    "    return hourly_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lagged_features(df, lag=1):\n",
    "    if not type(df) == pd.DataFrame:\n",
    "        df = pd.DataFrame(df, columns=['consumption'])\n",
    "    \n",
    "    def _rename_lag(ser, j):\n",
    "        ser.name = ser.name + f'_{j}'\n",
    "        return ser\n",
    "        \n",
    "    # add a column lagged by `i` steps\n",
    "    for i in range(1, lag + 1):\n",
    "        df = df.join(df.consumption.shift(i).pipe(_rename_lag, i))\n",
    "\n",
    "    df.dropna(inplace=True)\n",
    "    return df\n",
    "\n",
    "def prepare_training_data(consumption_vals, lag):\n",
    "    \"\"\" Converts a series of consumption data into a\n",
    "        lagged, scaled sample.\n",
    "    \"\"\"\n",
    "    # convert consumption series to lagged features\n",
    "    consumption_lagged = create_lagged_features(consumption_vals, lag=lag)\n",
    "\n",
    "    # X, y format taking the first column (original time series) to be the y\n",
    "    X = consumption_lagged.drop('consumption', axis=1).values\n",
    "    y = consumption_lagged.consumption.values\n",
    "    \n",
    "    # keras expects 3 dimensional X\n",
    "    X = X.reshape(X.shape[0], 1, X.shape[1])\n",
    "    \n",
    "    return X, y, scaler\n",
    "\n",
    "# root mean squared error or rmse\n",
    "def measure_rmse(actual, predicted):\n",
    "    return sqrt(mean_squared_error(actual, predicted))\n",
    "\n",
    "# walk-forward validation for univariate data\n",
    "def walk_forward_validation(train, test, cfg, scaler, group_col='series_id'):\n",
    "    errors = []\n",
    "    \n",
    "    # fit model\n",
    "    model = model_build(cfg)\n",
    "    model = model_fit(model, train_df, cfg)\n",
    "        \n",
    "    for ser_id, ser_data in test.groupby(group_col):\n",
    "        yhat = model_predict(model, train[train.series_id == ser_id].consumption, cfg, scaler, is_inverse_transform=False)\n",
    "        errors.append(measure_rmse(ser_data.consumption, yhat))\n",
    "        model.reset_states()\n",
    "\n",
    "    # estimate prediction error\n",
    "    error = np.mean(errors)\n",
    "    print(' > %.3f' % error)\n",
    "    return error\n",
    "\n",
    "# repeat evaluation of a config\n",
    "def repeat_evaluate(train, test, config, scaler, n_repeats=30):\n",
    "    # fit and evaluate the model n times\n",
    "    scores = [walk_forward_validation(train, test, config, scaler) for _ in range(n_repeats)]\n",
    "    return scores\n",
    "\n",
    "# summarize model performance\n",
    "def summarize_scores(name, scores):\n",
    "    # print a summary\n",
    "    scores_m, score_std = np.mean(scores), np.std(scores)\n",
    "    print('%s: %.3f RMSE (+/- %.3f)' % (name, scores_m, score_std)) # box and whisker plot\n",
    "    plt.boxplot(scores)\n",
    "    plt.show()\n",
    "\n",
    "def sampling_data(df, frac=0.01):\n",
    "    rng = np.random.RandomState(seed=RANDOM_SEED)\n",
    "    series_ids = df.series_id.unique()\n",
    "    series_mask = rng.binomial(1, frac, size=series_ids.shape).astype(bool)\n",
    "\n",
    "    training_series = series_ids[series_mask]\n",
    "\n",
    "    # reduce training data to series subset\n",
    "    return df[df.series_id.isin(training_series)]\n",
    "\n",
    "def train_test_split(df, n_test=24, group_col='series_id'):\n",
    "    df = df.copy()\n",
    "    train_df = pd.DataFrame()\n",
    "    test_df = pd.DataFrame()\n",
    "\n",
    "    for ser_id, ser_data in df.groupby(group_col):\n",
    "        split_train, split_test = ser_data[:-n_test], ser_data[-n_test:]\n",
    "        \n",
    "        split_train[group_col] = ser_id\n",
    "        split_test[group_col] = ser_id\n",
    "        \n",
    "        train_df = train_df.append(split_train)\n",
    "        test_df = test_df.append(split_test)\n",
    "    \n",
    "    return train_df, test_df\n",
    "\n",
    "def describe_training_data(train_df):\n",
    "    num_training_series = train_df.series_id.nunique()\n",
    "    num_training_days = num_training_series * 28\n",
    "    num_training_hours = num_training_days * 24\n",
    "    \n",
    "    desc = f'There are {num_training_series} training ' \\\n",
    "           f'series totaling {num_training_days} days ' \\\n",
    "           f'({num_training_hours} hours) of consumption data.'\n",
    "    \n",
    "    print(desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp_df = sampling_data(consumption_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 10 training series totaling 280 days (6720 hours) of consumption data.\n"
     ]
    }
   ],
   "source": [
    "describe_training_data(samp_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thuongdinh/.virtualenvs/mlcsef/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# scale training data\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "samp_df['consumption'] = scaler.fit_transform(samp_df['consumption'].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7392    0.494236\n",
       "7393    0.589000\n",
       "7394    0.615719\n",
       "7395    0.592363\n",
       "7396    0.600871\n",
       "Name: consumption, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samp_df['consumption'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thuongdinh/.virtualenvs/mlcsef/lib/python3.6/site-packages/ipykernel_launcher.py:75: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/thuongdinh/.virtualenvs/mlcsef/lib/python3.6/site-packages/ipykernel_launcher.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(samp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 10 training series totaling 280 days (6720 hours) of consumption data.\n"
     ]
    }
   ],
   "source": [
    "describe_training_data(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 10 training series totaling 280 days (6720 hours) of consumption data.\n"
     ]
    }
   ],
   "source": [
    "describe_training_data(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = [24, 24, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 0.291\n",
      " > 0.295\n",
      " > 0.284\n",
      " > 0.292\n",
      " > 0.287\n",
      " > 0.289\n",
      " > 0.293\n",
      " > 0.283\n",
      " > 0.289\n",
      " > 0.290\n",
      " > 0.301\n",
      " > 0.285\n",
      " > 0.288\n",
      " > 0.289\n",
      " > 0.291\n",
      " > 0.301\n",
      " > 0.296\n",
      " > 0.295\n",
      " > 0.297\n",
      " > 0.291\n",
      " > 0.297\n",
      " > 0.271\n",
      " > 0.294\n",
      " > 0.296\n",
      " > 0.287\n",
      " > 0.286\n",
      " > 0.296\n",
      " > 0.295\n",
      " > 0.294\n",
      " > 0.291\n"
     ]
    }
   ],
   "source": [
    "scores = repeat_evaluate(train_df, test_df, config, scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lstm: 0.291 RMSE (+/- 0.006)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAAF0xJREFUeJzt3X9s1PXh+PFnudYiaot3x6iUzuqt5KvUUJIL64pxFvoHmUvWoNkfGrPIEgxxYFwInQxdF9Okk/JDjEbDGiS5b5Q/FjSyxZHSmGathGZYmcAXKTQSaEnTOxJYFOF69/2D+9z302/Zp4f0F/p8/MX77sXrXu/k0ue9X9fe5aXT6TSSpO+9GVO9AEnS9GAQJEmAQZAkZRgESRJgECRJGQZBkgQYBElShkGQJAEGQZKUYRAkSQDkT/UCblR/f/9UL0EaJRwOMzQ0NNXLkK5r3rx5OY3zCkGSBBgESVKGQZAkAQZBkpRhECRJgEGQJGUYBEkSYBAkSRm33B+mSZOhtLR0Uh7n3Llzk/I4Ui4MgnQdN/qDurS01B/uuuW5ZSRJAgyCJCkjpy2jnp4edu3aRSqVYvny5dTX14+4f//+/fz9739nxowZzJw5k2effZb58+cDsHfvXtrb25kxYwbPPPMMVVVVOc0pSZpcY14hpFIpWltb2bhxI9u2baOzs5OzZ8+OGPPwww+zZcsWNm/ezC9+8Qt2794NwNmzZ+nq6mLr1q38/ve/p7W1lVQqldOckqTJNWYQent7KSkpYe7cueTn51NTU0N3d/eIMbNmzcr++/Lly+Tl5QHQ3d1NTU0NBQUF/OAHP6CkpITe3t6c5pQkTa4xt4wSiQShUCh7HAqFOHny5KhxH330EX/9619JJpO8/PLL2f9bUVGRHRMMBkkkEtl5xpoToK2tjba2NgCam5sJh8O5nJc06Xxu6lY3br92umLFClasWME//vEP/vKXv/Cb3/xmXOatq6ujrq4ue+yXkGi68rmp6WrcviAnGAwSj8ezx/F4nGAw+B/H//ftn////yYSCYLB4A3PKUmaeGMGIRKJMDAwwODgIMlkkq6uLqLR6IgxAwMD2X8fPnyYe+65B4BoNEpXVxdXr15lcHCQgYEBfvSjH+U0pyRpco25ZRQIBFi1ahVNTU2kUilqa2spKytjz549RCIRotEoH330Ef/6178IBALceeedPPfccwCUlZXxk5/8hN/+9rfMmDGDX//618yYca1B15tTkjR18tLpdHqqF3Ej+vv7p3oJ0ih+dIWms3F7D0GS9P1gECRJgEGQJGUYBEkSYBAkSRkGQZIEGARJUoZBkCQBBkGSlGEQJEmAQZAkZRgESRJgECRJGQZBkgQYBElShkGQJAEGQZKUYRAkSYBBkCRlGARJEmAQJEkZBkGSBBgESVJGfi6Denp62LVrF6lUiuXLl1NfXz/i/n379nHgwAECgQBFRUWsWbOGOXPmABCLxfj0008BePzxx6mpqQHgjTfe4NixY8yaNQuA5557jvLy8vE6L0nSDRozCKlUitbWVjZt2kQoFOLFF18kGo0yf/787Jjy8nKam5spLCxk//79xGIxXnjhBQ4fPkxfXx+vvvoqV69e5Y9//CNVVVXZCDz99NNUV1dP3NlJknI25pZRb28vJSUlzJ07l/z8fGpqauju7h4xprKyksLCQgAqKipIJBIAnD17lgceeIBAIMDMmTP54Q9/SE9PzwSchiTpZo0ZhEQiQSgUyh6HQqHsD/zraW9vp6qqCoB7772Xzz77jG+++YaLFy9y9OhR4vF4duy7777L+vXreeedd7h69erNnIck6Sbl9B5Crjo6Ojh9+jSNjY0ALFq0iFOnTrFp0yaKiopYsGABM2Zca9CTTz7J7NmzSSaTvP3223zwwQc88cQTo+Zsa2ujra0NgObmZsLh8HguWd8DJSUlXLhwYcIfp7S0dELnv/vuuzl//vyEPoa+38YMQjAYHPGqPh6PEwwGR407cuQIe/fupbGxkYKCguztK1euZOXKlQC89tpr3HPPPcC1JzdAQUEBtbW1fPjhh9d9/Lq6Ourq6rLHQ0NDuZyXlHXhwgXOnTs3oY8RDocn/LlZWlrq81/fyrx583IaN+aWUSQSYWBggMHBQZLJJF1dXUSj0RFj+vr62LlzJxs2bKC4uDh7eyqV4tKlSwB8+eWXnDlzhkWLFgFkX7Gl02m6u7spKyvL7cwkSRNizCuEQCDAqlWraGpqIpVKUVtbS1lZGXv27CESiRCNRonFYly+fJmtW7cC114tNTQ0kEwmefnllwGYNWsWa9euJRAIALBjxw4uXrwIXHuvYfXq1RN1jpKkHOSl0+n0VC/iRvT390/1EnSLKS0t/c5sGU30eei7ady2jCRJ3w8GQZIEGARJUoZBkCQBBkGSlGEQJEmAQZAkZRgESRJgECRJGQZBkgQYBElShkGQJAEGQZKUYRAkSYBBkCRlGARJEmAQJEkZBkGSBBgESVKG36ms77xf/O//M9VLGDcfPPW/pnoJugXl+p3KBkHfeZPx5fThcJihoaEJfYzJOA99N+UaBLeMJEmAQZAkZRgESRIA+bkM6unpYdeuXaRSKZYvX059ff2I+/ft28eBAwcIBAIUFRWxZs0a5syZA0AsFuPTTz8F4PHHH6empgaAwcFBtm/fzqVLl7j//vtZu3Yt+fk5LUeSNAHGvEJIpVK0trayceNGtm3bRmdnJ2fPnh0xpry8nObmZlpaWqiuriYWiwFw+PBh+vr6ePXVV2lqauLDDz/kq6++Aq6F4rHHHuP111/njjvuoL29fQJOT5KUqzGD0NvbS0lJCXPnziU/P5+amhq6u7tHjKmsrKSwsBCAiooKEokEAGfPnuWBBx4gEAgwc+ZMfvjDH9LT00M6nebo0aNUV1cD8Oijj46aU5I0ucYMQiKRIBQKZY9DoVD2B/71tLe3U1VVBcC9997LZ599xjfffMPFixc5evQo8XicS5cuMWvWLAKBAADBYPB/nFOSNPHGddO+o6OD06dP09jYCMCiRYs4deoUmzZtoqioiAULFjBjxo29j93W1kZbWxsAzc3NhMPh8Vyyvicm+nmTn58/Kc9Nn/+aSGMGIRgMEo/Hs8fxeJxgMDhq3JEjR9i7dy+NjY0UFBRkb1+5ciUrV64E4LXXXuOee+7hrrvu4quvvmJ4eJhAIEAikbjunAB1dXXU1dVljyf6j3/03TTRz5vJ+MM08Pmvb2fc/jAtEokwMDDA4OAgyWSSrq4uotHoiDF9fX3s3LmTDRs2UFxcnL09lUpx6dIlAL788kvOnDnDokWLyMvLY+HChRw8eBCAjz/+eNSckqTJNeYVQiAQYNWqVTQ1NZFKpaitraWsrIw9e/YQiUSIRqPEYjEuX77M1q1bgWuvlhoaGkgmk7z88ssAzJo1i7Vr12bfN3jqqafYvn077733Hvfddx/Lli2bwNOUJI3FzzLSd56fZaTvOz/LSJJ0QwyCJAkwCJKkDIMgSQIMgiQpwyBIkoBx/ugKaboqLS2d6iXctNmzZ0/1EvQdZxD0nTcZv7vv3wjou8AtI0kSYBAkSRkGQZIEGARJUoZBkCQBBkGSlGEQJEmAQZAkZRgESRJgECRJGQZBkgQYBElShkGQJAEGQZKUYRAkSYBBkCRl5PQFOT09PezatYtUKsXy5cupr68fcf++ffs4cOAAgUCAoqIi1qxZw5w5cwCIxWIcPnyYdDrNQw89xDPPPENeXh6NjY1cuHCB2267DYBNmzZRXFw8zqcnScrVmEFIpVK0trayadMmQqEQL774ItFolPnz52fHlJeX09zcTGFhIfv37ycWi/HCCy9w4sQJTpw4QUtLCwAvvfQSx44dY+HChQCsW7eOSCQyQacmSboRY24Z9fb2UlJSwty5c8nPz6empobu7u4RYyorKyksLASgoqKCRCIBQF5eHleuXCGZTHL16lWGh4e9CpCkaWrMK4REIkEoFMoeh0IhTp48+R/Ht7e3U1VVBcCCBQtYuHAhq1evJp1Os2LFihFXFm+++SYzZszgxz/+MY8//jh5eXmj5mtra6OtrQ2A5uZmwuFw7mcnTSKfm7rV5fQeQq46Ojo4ffo0jY2NAJw/f55z587x1ltvAfDKK69w/PhxHnjgAdatW0cwGOTrr79my5YtdHR08NOf/nTUnHV1ddTV1WWPh4aGxnPJ0rjxuanpat68eTmNG3PLKBgMEo/Hs8fxeJxgMDhq3JEjR9i7dy8bNmygoKAAgEOHDlFRUcHMmTOZOXMmixcv5osvvsjOC3D77bfz8MMP09vbm9OCJUkTY8wgRCIRBgYGGBwcJJlM0tXVRTQaHTGmr6+PnTt3smHDhhHvEYTDYY4fP87w8DDJZJJjx45RWlrK8PAwFy9eBCCZTPLPf/6TsrKycT41SdKNGHPLKBAIsGrVKpqamkilUtTW1lJWVsaePXuIRCJEo1FisRiXL19m69atwLUQNDQ0UF1dzeeff8769esBqKqqIhqNcvnyZZqamhgeHiaVSvHQQw+N2BaSJE2+vHQ6nZ7qRdyI/v7+qV6CNEppaSnnzp2b6mVI1zVu7yFIkr4fDIIkCTAIkqQMgyBJAgyCJCnDIEiSAIMgScowCJIkwCBIkjIMgiQJGOePv5a+K0pLSyfl//hxF5pODIJ0HTf6gzocDvt9CLrluWUkSQIMgiQpwyBIkgCDIEnKMAiSJMAgSJIyDIIkCTAIkqQMgyBJAgyCJCnDIEiSgBw/y6inp4ddu3aRSqVYvnw59fX1I+7ft28fBw4cIBAIUFRUxJo1a5gzZw4AsViMw4cPk06neeihh3jmmWfIy8vj9OnTvPHGG1y5coXFixdnb5ckTY0xrxBSqRStra1s3LiRbdu20dnZydmzZ0eMKS8vp7m5mZaWFqqrq4nFYgCcOHGCEydO0NLSwpYtWzh16hTHjh0DYOfOnTz77LPs2LGD8+fP09PTMwGnJ0nK1ZhB6O3tpaSkhLlz55Kfn09NTQ3d3d0jxlRWVlJYWAhARUUFiUQCgLy8PK5cuUIymeTq1asMDw9TXFzMhQsX+Prrr1mwYAF5eXk88sgjo+aUJE2uMbeMEokEoVAoexwKhTh58uR/HN/e3k5VVRUACxYsYOHChaxevZp0Os2KFSuYP38+p06dGjXnf0VEkjQ1xvX7EDo6Ojh9+jSNjY0AnD9/nnPnzvHWW28B8Morr3D8+HFuu+22nOdsa2ujra0NgObmZsLh8HguWRoX+fn5Pjd1yxszCMFgkHg8nj2Ox+MEg8FR444cOcLevXtpbGykoKAAgEOHDlFRUcHMmTMBWLx4MV988QWPPPJITnMC1NXVUVdXlz32S0g0HfkFOZrO5s2bl9O4Md9DiEQiDAwMMDg4SDKZpKuri2g0OmJMX18fO3fuZMOGDRQXF2dvD4fDHD9+nOHhYZLJJMeOHaO0tJS7776b22+/nS+++IJ0Ok1HR8eoOSVJkysvnU6nxxp0+PBhdu/eTSqVora2lpUrV7Jnzx4ikQjRaJRXXnmFM2fOMHv2bOBaCBoaGkilUvz5z3/m+PHjAFRVVfGrX/0KgFOnTvHmm29y5coVqqqqWLVqVU6/dtrf338z5ytNCK8QNJ3leoWQUxCmE4Og6cggaDobty0jSdL3g0GQJAEGQZKUYRAkSYBBkCRlGARJEmAQJEkZBkGSBBgESVKGQZAkAQZBkpRhECRJgEGQJGUYBEkSYBAkSRkGQZIEGARJUoZBkCQBBkGSlGEQJEmAQZAkZRgESRJgECRJGQZBkgRAfi6Denp62LVrF6lUiuXLl1NfXz/i/n379nHgwAECgQBFRUWsWbOGOXPm8Pnnn7N79+7suP7+fp5//nmWLFnCG2+8wbFjx5g1axYAzz33HOXl5eN3ZpKkGzJmEFKpFK2trWzatIlQKMSLL75INBpl/vz52THl5eU0NzdTWFjI/v37icVivPDCC1RWVrJ582YA/v3vf7N27VoWLVqU/X9PP/001dXVE3BakqQbNeaWUW9vLyUlJcydO5f8/Hxqamro7u4eMaayspLCwkIAKioqSCQSo+Y5ePAgixcvzo6TJE0vYwYhkUgQCoWyx6FQ6Lo/8P9Le3s7VVVVo27v7Oxk6dKlI2579913Wb9+Pe+88w5Xr169kXVLksZZTu8h5Kqjo4PTp0/T2Ng44vYLFy5w5syZEdtFTz75JLNnzyaZTPL222/zwQcf8MQTT4yas62tjba2NgCam5sJh8PjuWRpXOTn5/vc1C1vzCAEg0Hi8Xj2OB6PEwwGR407cuQIe/fupbGxkYKCghH3ffLJJyxZsoT8/P/3cHfffTcABQUF1NbW8uGHH1738evq6qirq8seDw0NjbVkadKFw2Gfm5q25s2bl9O4MbeMIpEIAwMDDA4Okkwm6erqIhqNjhjT19fHzp072bBhA8XFxaPmuN520YULFwBIp9N0d3dTVlaW04IlSRNjzCuEQCDAqlWraGpqIpVKUVtbS1lZGXv27CESiRCNRonFYly+fJmtW7cC114tNTQ0ADA4OMjQ0BAPPvjgiHl37NjBxYsXAbj33ntZvXr1eJ+bJOkG5KXT6fRUL+JG9Pf3T/USpFHcMtJ0Nm5bRpKk7weDIEkCDIIkKcMgSJIAgyBJyjAIkiTAIEiSMgyCJAkwCJKkDIMgSQIMgiQpwyBIkgCDIEnKMAiSJMAgSJIyDIIkCTAIkqQMgyBJAgyCJCnDIEg34f3332fZsmXcfvvtLFu2jPfff3+qlyR9a/lTvQDpVvX+++/zpz/9iZaWFn72s5/xt7/9jfXr1wNQX18/xauTbpxXCNK3tGPHDlpaWli6dCkFBQUsXbqUlpYWduzYMdVLk74VgyB9SydPnmTJkiUjbluyZAknT56cohVJNyenLaOenh527dpFKpVi+fLloy6H9+3bx4EDBwgEAhQVFbFmzRrmzJnD559/zu7du7Pj+vv7ef7551myZAmDg4Ns376dS5cucf/997N27Vry893B0q2joqKCQ4cOsXTp0uxthw4doqKiYgpXJX17Y14hpFIpWltb2bhxI9u2baOzs5OzZ8+OGFNeXk5zczMtLS1UV1cTi8UAqKysZPPmzWzevJk//OEP3HbbbSxatAiAWCzGY489xuuvv84dd9xBe3v7BJyeNHHWrVvH+vXr6ezs5OrVq3R2drJ+/XrWrVs31UuTvpUxg9Db20tJSQlz584lPz+fmpoauru7R4yprKyksLAQuPaqKZFIjJrn4MGDLF68mMLCQtLpNEePHqW6uhqARx99dNSc0nRXX19PQ0MDL730EkVFRbz00ks0NDT4hrJuWWPu0SQSCUKhUPY4FAr9j3uk7e3tVFVVjbq9s7OTn//85wBcunSJWbNmEQgEAAgGg9eNiDTd1dfXU19fTzgcZmhoaKqXI92Ucd207+jo4PTp0zQ2No64/cKFC5w5cya7XXQj2traaGtrA6C5uZlwODweS5XGVX5+vs9N3fLGDEIwGCQej2eP4/E4wWBw1LgjR46wd+9eGhsbKSgoGHHfJ598wpIlS7JvGt9111189dVXDA8PEwgESCQS150ToK6ujrq6uuyxr8I0HXmFoOls3rx5OY0b8z2ESCTCwMAAg4ODJJNJurq6iEajI8b09fWxc+dONmzYQHFx8ag5Ojs7R/wmRl5eHgsXLuTgwYMAfPzxx6PmlCRNrjGvEAKBAKtWraKpqYlUKkVtbS1lZWXs2bOHSCRCNBolFotx+fJltm7dClx7tdTQ0ADA4OAgQ0NDPPjggyPmfeqpp9i+fTvvvfce9913H8uWLZuA05Mk5SovnU6np3oRN6K/v3+qlyCN4paRprNct4xuuSBIkiaGH10hjYPf/e53U70E6aYZBEkSYBAkSRkGQRoH//1vZaRblW8qS5IArxAkSRl+AYF0E958800OHz5McXExW7ZsmerlSDfFKwTpJjz66KNs3LhxqpchjQuDIN2EBx98kDvvvHOqlyGNC4MgSQIMgiQpwyBIkgCDIEnK8A/TpJuwfft2jh07xqVLlyguLuaXv/yl3+2hW5ZBkCQBbhlJkjIMgiQJMAiSpAyDIEkCDIIkKcMgSJIAgyBJyjAIkiQA/i8cEFTlJ/tDMAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summarize_scores('lstm', scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
